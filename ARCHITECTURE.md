# Architecture Documentation: podfeedfilter

*Generated by AI evaluation on 2025-08-29*

## System Overview

**podfeedfilter** is a command-line tool built with a clean 3-layer architecture that processes RSS podcast feeds through keyword filtering and generates customized output feeds.

## Architectural Principles

### 1. Separation of Concerns
Each module has a single, well-defined responsibility:
- **CLI Layer**: User interface and argument processing
- **Configuration Layer**: YAML parsing and validation
- **Core Layer**: Feed processing and filtering logic

### 2. Dependency Inversion
Core business logic doesn't depend on external libraries directly, using abstraction layers where appropriate.

### 3. Fail-Fast Philosophy
Input validation happens early, with clear error messages for configuration issues.

### 4. Idempotent Operations
Running the same configuration multiple times produces consistent, predictable results.

## System Architecture Diagram

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   CLI Layer     │    │ Configuration    │    │   Core Layer    │
│  (__main__.py)  │───▶│    (config.py)   │───▶│  (filterer.py)  │
│                 │    │                  │    │                 │
│ • Arg parsing   │    │ • YAML loading   │    │ • Feed fetching │
│ • Orchestration │    │ • FeedConfig     │    │ • Filtering     │
│ • CLI overrides │    │ • Validation     │    │ • RSS generation│
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       ▼
         │                       │              ┌─────────────────┐
         │                       │              │ External Deps   │
         │                       │              │                 │
         │                       │              │ • feedparser    │
         │                       │              │ • feedgen       │
         │                       │              │ • requests      │
         │                       └──────────────┤ • PyYAML        │
         │                                      └─────────────────┘
         ▼
┌─────────────────┐
│  File System    │
│                 │
│ • Input YAML    │
│ • Output RSS    │
│ • HTTP Cache    │
└─────────────────┘
```

## Component Architecture

### 1. CLI Layer (`__main__.py`)

**Responsibility**: Entry point and command-line interface

```python
def main() -> None:
    # Parse command-line arguments
    parser = argparse.ArgumentParser()
    args = parser.parse_args()
    
    # Load configuration
    feeds = load_config(args.config)
    
    # Apply CLI overrides
    if args.private is not None:
        for feed in feeds:
            feed.private = args.private.lower() == "true"
    
    # Process each feed
    for feed in feeds:
        process_feed(feed, no_check_modified=args.no_check_modified)
```

**Key Features**:
- Minimal orchestration logic
- Clear separation from business logic
- Support for global CLI overrides
- Simple, focused interface

### 2. Configuration Layer (`config.py`)

**Responsibility**: Configuration parsing and data structures

#### Core Data Structure
```python
@dataclass
class FeedConfig:
    url: str                        # Source feed URL
    output: str                     # Output file path
    include: List[str] = field(default_factory=list)  # Include keywords
    exclude: List[str] = field(default_factory=list)  # Exclude keywords
    title: str | None = None        # Override feed title
    description: str | None = None  # Override description
    check_modified: bool = True     # Enable HTTP caching
    private: bool = True            # Privacy control
```

#### Configuration Processing
```python
def load_config(path: str) -> List[FeedConfig]:
    # Parse YAML file
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    
    feeds: List[FeedConfig] = []
    for item in data.get("feeds", []):
        # Create main feed config (if applicable)
        if has_main_config(item):
            feeds.append(create_feed_config(item))
        
        # Create split configurations
        for split in item.get("splits", []):
            feeds.append(create_split_config(item, split))
    
    return feeds
```

**Key Features**:
- Type-safe configuration with dataclasses
- Support for feed splitting (1→N mapping)
- Robust bool() casting for configuration values
- Clear default value handling

### 3. Core Processing Layer (`filterer.py`)

**Responsibility**: Feed processing, filtering, and RSS generation

#### Main Processing Function
```python
def process_feed(cfg: FeedConfig, no_check_modified: bool = False):
    # 1. Load existing feed (if exists)
    existing_entries, existing_ids = load_existing_feed(cfg.output)
    
    # 2. Fetch remote feed (with conditional requests)
    remote_feed = fetch_remote_feed(cfg.url, cfg.check_modified, no_check_modified)
    
    # 3. Filter new episodes
    new_entries = filter_new_episodes(remote_feed, existing_ids, cfg)
    
    # 4. Generate output RSS feed
    generate_output_feed(cfg, existing_entries, new_entries)
```

#### Filtering Pipeline
```python
# Text matching (case-insensitive)
def _text_matches(text: str, keywords: list[str]) -> bool:
    lower = text.lower()
    return any(kw.lower() in lower for kw in keywords)

# Episode filtering logic
def _entry_passes(entry: feedparser.FeedParserDict, include: list[str], exclude: list[str]) -> bool:
    content = f"{entry.get('title', '')} {entry.get('description', '')} {entry.get('summary', '')}"
    
    # Exclude filter (fails if any exclude keyword matches)
    if exclude and _text_matches(content, exclude):
        return False
    
    # Include filter (passes only if include keyword matches, or no include filter)
    if include and not _text_matches(content, include):
        return False
    
    return True
```

#### HTTP Optimization
```python
def _conditional_fetch(url: str, since: float | None) -> tuple[bytes | None, float | None]:
    headers = {}
    if since is not None:
        headers["If-Modified-Since"] = email.utils.formatdate(since, usegmt=True)
    
    resp = requests.get(url, headers=headers, timeout=30)
    
    # Handle 304 Not Modified
    if resp.status_code == 304:
        return None, None
    
    # Extract Last-Modified timestamp
    lm_str = resp.headers.get("Last-Modified")
    lm_ts = parse_last_modified(lm_str) if lm_str else None
    
    return resp.content, lm_ts
```

## Data Flow Architecture

### 1. Configuration Flow
```
YAML File → yaml.safe_load() → dict → FeedConfig objects → List[FeedConfig]
```

### 2. Feed Processing Flow
```
RSS URL → HTTP Request → feedparser.parse() → Filter Logic → feedgen → Output RSS
```

### 3. Caching Flow
```
Last-Modified Header → File Timestamp → If-Modified-Since → 304 Not Modified → Skip Processing
```

### 4. Filtering Flow
```
Episode Content → Text Extraction → Keyword Matching → Include/Exclude Logic → Pass/Fail Decision
```

## Error Handling Architecture

### 1. Graceful Degradation Strategy
- HTTP conditional requests fall back to regular requests on failure
- Network failures are reported but don't crash the application
- Malformed RSS feeds are processed with available data

### 2. Error Boundaries
```python
# Network errors
try:
    content, last_modified_ts = _conditional_fetch(cfg.url, file_mtime)
except (requests.RequestException, ValueError) as e:
    print(f"Warning: Conditional fetch failed for {cfg.url}: {e}")
    print("Falling back to regular fetch...")
    remote = feedparser.parse(cfg.url)
```

### 3. Validation Strategy
- Input validation at configuration parsing time
- Type safety through dataclasses and type hints
- Clear error messages for user-facing issues

## Performance Architecture

### 1. HTTP Optimization
- **Conditional Requests**: Use `If-Modified-Since` headers to avoid unnecessary downloads
- **Timeout Handling**: 30-second timeout for HTTP requests
- **Smart Caching**: File timestamps reflect actual content changes

### 2. Processing Optimization
- **Append-only Logic**: Process only new episodes, preserve existing ones
- **Early Exit**: Stop processing when no matching episodes found
- **Memory Efficiency**: Stream processing without loading entire feeds into memory

### 3. I/O Optimization
- **Batch Processing**: Process all feeds in single execution
- **File Timestamp Management**: Update timestamps only when content changes
- **Path Safety**: Use `pathlib` for cross-platform file handling

## Security Architecture

### 1. Input Security
- YAML parsing with `safe_load()` (no code execution)
- Path validation using `pathlib`
- Type validation through dataclasses

### 2. Network Security
- Timeout protection against slow/malicious servers
- No authentication (assumes public feeds)
- HTTPS support through `requests` library

### 3. Output Security
- Safe file creation with `parents=True, exist_ok=True`
- No shell command execution
- Controlled output directory creation

## Extensibility Architecture

### 1. Plugin Points
The architecture supports extension at several points:

- **Custom Filters**: Add new filtering logic beyond keywords
- **Output Formats**: Support formats beyond RSS (JSON, OPML)
- **Data Sources**: Support sources beyond HTTP URLs
- **Processing Hooks**: Pre/post processing capabilities

### 2. Configuration Extension
```yaml
feeds:
  - url: "..."
    output: "..."
    # Extension point: custom filtering
    custom_filters:
      - type: "regex"
        pattern: "..."
    # Extension point: additional metadata
    metadata:
      author: "..."
      category: "..."
```

### 3. Future Architecture Considerations
- **Plugin System**: Load custom filters from external modules
- **Event System**: Pub/sub architecture for processing events
- **Database Backend**: Optional persistent storage for episode tracking
- **API Layer**: REST API for programmatic access

## Testing Architecture

### 1. Test Structure
```
tests/
├── Unit Tests (test_*.py)
├── Integration Tests (test_*_integration.py)
├── Edge Case Tests (test_edge_cases.py)
└── Performance Tests (embedded in edge cases)
```

### 2. Mock Strategy
- **External Dependencies**: HTTP requests, file system operations
- **Time-based Testing**: `freezegun` for timestamp testing
- **Network Mocking**: `responses` library for HTTP mocking

### 3. Coverage Strategy
- **100% line coverage** on core modules (`config.py`, `filterer.py`)
- **Comprehensive edge case testing**
- **Performance benchmarking** with realistic datasets

## Deployment Architecture

### 1. Distribution
- **Python Package**: Installable via `pip`
- **Command-line Tool**: Accessible as `python -m podfeedfilter`
- **Self-contained**: No external system dependencies

### 2. Runtime Requirements
- **Python 3.10+**: Modern type hint syntax
- **Operating System**: Cross-platform (Linux, macOS, Windows)
- **Memory**: Low memory footprint (< 100MB typical)
- **Network**: HTTP/HTTPS access to RSS feeds

### 3. CI/CD Architecture
```yaml
GitHub Actions:
  - Multi-version Python testing (3.10, 3.11, 3.12, 3.13)
  - Pylint code quality analysis
  - Test coverage reporting
  - Artifact generation for debugging
```

## Conclusion

The architecture of **podfeedfilter** demonstrates several key strengths:

1. **Clean Separation**: Each layer has clear responsibilities and minimal coupling
2. **Robustness**: Comprehensive error handling and graceful degradation
3. **Performance**: HTTP optimization and smart caching strategies
4. **Maintainability**: Small, focused modules with excellent test coverage
5. **Extensibility**: Well-defined extension points for future enhancements

This architecture supports the current feature set effectively while providing a solid foundation for future growth and enhancement.
